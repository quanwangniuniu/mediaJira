services:
  # Redis Service for WebSocket functionality
  redis:
    image: redis:7-alpine
    container_name: redis-dev
    restart: always
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # SonarQube
  sonarqube:
    build: 
      context: ./devops/sonarqube
      dockerfile: Dockerfile.dev
    container_name: sonarqube-dev
    restart: always
    ports:
      - "9000:9000"
    env_file:
      - .env
    environment:
      - SONAR_USER=${SONAR_USER}
      - SONAR_PWD=${SONAR_PWD}
    volumes:
      - sonar-token-data:/token
      - ./devops/sonarqube/init-sonar:/docker-entrypoint-init.d/init-sonar
    command: ["/bin/bash", "/docker-entrypoint-init.d/init-sonar"]
    healthcheck:
      test: ["CMD-SHELL", "curl -u ${SONAR_USER}:${SONAR_PWD} -s http://localhost:9000/api/system/health | grep -q GREEN || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s


  # ClamAV Service for virus scanning
  clamav:
    image: clamav/clamav:latest
    platform: linux/amd64
    container_name: clamav-dev
    restart: always
    ports:
      - "3310:3310"
    volumes:
      - clamav_data:/var/lib/clamav
    healthcheck:
      test: ["CMD", "clamdscan", "--version"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Django Backend (Development)
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile.dev
    container_name: backend-dev
    restart: always
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - DB_HOST=host.docker.internal
      - DEBUG=True
      - SONAR_USER=${SONAR_USER}
      - SONAR_PWD=${SONAR_PWD}
      - OTEL_SERVICE_NAME=django-backend
      - OTEL_TRACES_SAMPLER=always_on
      - KAFKA_BROKER=${KAFKA_BROKER}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
      clamav:
        condition: service_healthy
      sonarqube:
        condition: service_healthy
    volumes:
      - sonar-token-data:/token
    command: ["/bin/bash", "/app/entrypoint-dev"]
    logging:
      driver: "fluentd"
      options:
        fluentd-address: localhost:24224
        tag: django    

  # Next.js Frontend (Development)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: frontend-dev
    restart: always
    ports:
      - "3000:3000"
    env_file:
      - .env
    volumes:
      - frontend_node_modules:/app/node_modules
      - frontend_next:/app/.next
      - sonar-token-data:/token
    environment:
      - WATCHPACK_POLLING=true
      - CHOKIDAR_USEPOLLING=true
      - SONAR_USER=${SONAR_USER}
      - SONAR_PWD=${SONAR_PWD}
      - KAFKA_BROKER=${KAFKA_BROKER}
    depends_on:
      - backend
      - sonarqube
    command: ["/bin/bash", "/app/entrypoint-dev"]
    logging:
      driver: "fluentd"
      options:
        fluentd-address: localhost:24224
        tag: nextjs    

  # Nginx Reverse Proxy
  nginx:
    image: nginx:latest
    container_name: nginx-dev
    restart: always
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - backend
      - frontend

  # Celery Worker for background tasks
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    container_name: celery-worker-dev
    restart: always
    env_file:
      - .env
    environment:
      - DB_HOST=host.docker.internal
      - DEBUG=True
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
      clamav:
        condition: service_healthy
    volumes:
      - ./backend:/app
    command: celery -A backend worker --loglevel=info

  # Ngrok tunnel service
  ngrok:
    image: ngrok/ngrok:latest
    container_name: ngrok-dev
    restart: always
    env_file:
      - .env
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
    volumes:
      - ./ngrok.yml:/etc/ngrok.yml:ro
    command: start --all --config /etc/ngrok.yml
    depends_on:
      - backend

  prometheus:
    image: prom/prometheus
    volumes:
      - ./devops/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    depends_on:
      - backend
      - frontend

  loki:
    image: grafana/loki:2.9.0
    ports:
      - "3100:3100"

  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
    depends_on:
      - backend
      - frontend
      - prometheus

  fluentbit:
    image: fluent/fluent-bit:latest
    volumes:
      - ./devops/fluentbit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf
    ports:
      - "2020:2020"  
      - "24224:24224"
      
  jaeger:
    image: jaegertracing/all-in-one:1.57
    restart: always
    ports:
      - "16686:16686"   # Jaeger UI
      - "6831:6831/udp" # Agent UDP
    depends_on:
      - backend
      - frontend


  kafka:
    image: confluentinc/cp-kafka:7.6.0
    restart: always
    ports:
      - "9092:9092"      # INTERNAL listener (for containers)
      - "29092:29092"    # EXTERNAL listener (for host/CI)
      - "1234:1234"     # Confluent Metrics endpoint
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Topic management - auto-creation disabled (topics must be pre-defined)
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CLUSTER_ID: "MW-7IGsmQbmFkrf2x7Ho5A"
      # Retention policy (7 days default)
      KAFKA_LOG_RETENTION_HOURS: 168
      
      # Security Configuration (PLAINTEXT for dev, see KAFKA_SECURITY.md for production)
      # Current: PLAINTEXT (no authentication/encryption) - OK for local development only
      # Production: Use SASL_SSL with SCRAM-SHA-512 authentication and SSL encryption
      
      # === PRODUCTION SECURITY SETTINGS (uncomment and configure for production) ===
      # 
      # 1. Update listener security protocol map to use SASL_SSL:
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:SASL_SSL,EXTERNAL:SASL_SSL,CONTROLLER:PLAINTEXT
      #
      # 2. Enable SASL mechanism:
      # KAFKA_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512
      # KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512
      #
      # 3. Configure JAAS (Java Authentication and Authorization Service):
      # KAFKA_OPTS: >-
      #   -Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf
      #   -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=9999:/config/kafka.yml
      # Mount JAAS config file in volumes: ./devops/kafka/kafka_server_jaas.conf:/etc/kafka/kafka_server_jaas.conf:ro
      #
      # 4. SSL/TLS Configuration (generate certificates first):
      # KAFKA_SSL_KEYSTORE_LOCATION: /var/ssl/private/kafka.server.keystore.jks
      # KAFKA_SSL_KEYSTORE_PASSWORD: ${KAFKA_SSL_KEYSTORE_PASSWORD}
      # KAFKA_SSL_KEY_PASSWORD: ${KAFKA_SSL_KEY_PASSWORD}
      # KAFKA_SSL_TRUSTSTORE_LOCATION: /var/ssl/private/kafka.server.truststore.jks
      # KAFKA_SSL_TRUSTSTORE_PASSWORD: ${KAFKA_SSL_TRUSTSTORE_PASSWORD}
      # KAFKA_SSL_CLIENT_AUTH: required
      # KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      # Mount SSL certificates in volumes: ./devops/kafka/ssl:/var/ssl/private:ro
      #
      # 5. Access Control Lists (ACLs) - enable for fine-grained authorization:
      # KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      # KAFKA_SUPER_USERS: User:admin
      #
      # See KAFKA_SECURITY.md for detailed security setup instructions
    volumes:
      - kafka_data:/var/lib/kafka/data   
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9092"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s

      
  kafka-exporter:
    image: danielqsj/kafka-exporter
    container_name: kafka-exporter
    restart: always
    ports:
      - "9308:9308"
    command:
      - "--kafka.server=kafka:9092"   
    depends_on:
      - kafka

  kafka-ui:
    # Kafka UI for cluster management and monitoring
    # Configured for KRaft mode (no Zookeeper dependency)
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    restart: always
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      # Note: Zookeeper not needed in KRaft mode - metadata managed by Kafka controllers
      # KAFKA_CLUSTERS_0_ZOOKEEPER removed - using bootstrap servers only
    depends_on:
      kafka:
        condition: service_healthy

  topic-init:
    build:
      context: ./devops/topic-init
      dockerfile: Dockerfile.dev
    container_name: topic-init
    restart: always
    entrypoint: ["/bin/bash", "/usr/local/bin/entrypoint-dev"]
    depends_on:
      kafka:
        condition: service_healthy


  kcat:
    image: edenhill/kcat:1.7.1
    container_name: kcat
    entrypoint: ["sh", "-c", "sleep 999999"]

  # InfluxDB for K6 metrics
  influxdb:
    image: influxdb:2.7-alpine
    container_name: influxdb-k6
    restart: always
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USER:-admin}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PASSWORD:-adminpassword}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUXDB_ORG:-k6}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUXDB_BUCKET:-k6}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUXDB_TOKEN:-}
    volumes:
      - influxdb_k6_data:/var/lib/influxdb2
      - influxdb_k6_config:/etc/influxdb2
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8086/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - grafana

volumes:
  clamav_data: 
  sonar-token-data:
  frontend_node_modules:
  frontend_next:
  kafka_data:
  influxdb_k6_data:
  influxdb_k6_config: