# æ•°æ®è¾“å…¥å®Œæ•´æŒ‡å—

## ğŸ¯ **ä½ æ˜¯å¯¹çš„ï¼æ•°æ®è¾“å…¥è¿™éƒ¨åˆ†ç¡®å®å¾ˆå…³é”®**

ç›®å‰çš„å®ç°ç¡®å®å­˜åœ¨æ•°æ®è¾“å…¥çš„å…³é”®ç¼ºå¤±ã€‚è®©æˆ‘è¯¦ç»†è¯´æ˜ç°åœ¨æœ‰ä»€ä¹ˆï¼Œç¼ºå°‘ä»€ä¹ˆï¼Œä»¥åŠå¦‚ä½•å®Œå–„ã€‚

## âœ… **ç°åœ¨å·²æœ‰çš„æ•°æ®è¾“å…¥æ–¹å¼**

### 1. é€šè¿‡APIç›´æ¥åˆ›å»ºReportæ—¶è¾“å…¥æ•°æ®
```http
POST /api/reports/reports/
{
  "id": "q1_report_2024",
  "title": "2024å¹´Q1è¥é”€æŠ¥å‘Š",
  "slice_config": {
    // æ–¹å¼1: ç›´æ¥å†…è”æ•°æ®
    "inline_data": {
      "columns": ["Campaign", "Cost", "Revenue"],
      "rows": [
        ["Facebook Ads", 50000, 125000],
        ["Google Ads", 40000, 100000]
      ]
    }
  }
}
```

### 2. é€šè¿‡APIæ›´æ–°Reportçš„slice_config
```http
PUT /api/reports/reports/q1_report_2024/
{
  "slice_config": {
    "inline_result": {
      "campaign_performance": {
        "columns": ["Campaign", "Cost", "Revenue", "ROI"],
        "rows": [
          ["Facebook Ads", 50000, 125000, 150],
          ["Google Ads", 40000, 100000, 150],
          ["TikTok Ads", 30000, 90000, 200]
        ]
      }
    }
  }
}
```

## âŒ **ç›®å‰ç¼ºå°‘çš„å…³é”®æ•°æ®è¾“å…¥åŠŸèƒ½**

### 1. æ–‡ä»¶ä¸Šä¼ æ•°æ®è¾“å…¥
**ç¼ºå°‘**: CSV/Excelæ–‡ä»¶ä¸Šä¼ API
**éœ€è¦**: 
- æ–‡ä»¶ä¸Šä¼ æ¥å£
- CSVè§£æå’ŒéªŒè¯
- æ•°æ®é¢„è§ˆåŠŸèƒ½
- é”™è¯¯å¤„ç†å’Œæ ¼å¼éªŒè¯

### 2. å¤–éƒ¨æ•°æ®æºé›†æˆ
**ç¼ºå°‘**: è¿æ¥å¤–éƒ¨æ•°æ®åº“/APIçš„æœºåˆ¶
**éœ€è¦**:
- æ•°æ®æºé…ç½®ç®¡ç†
- APIè¿æ¥å™¨
- æ•°æ®åˆ·æ–°æœºåˆ¶
- è®¤è¯å’Œæƒé™ç®¡ç†

### 3. æ•°æ®ç¼–è¾‘å’Œç®¡ç†ç•Œé¢
**ç¼ºå°‘**: åœ¨çº¿æ•°æ®ç¼–è¾‘åŠŸèƒ½
**éœ€è¦**:
- è¡¨æ ¼ç¼–è¾‘å™¨
- æ•°æ®éªŒè¯
- å®æ—¶é¢„è§ˆ
- ç‰ˆæœ¬æ§åˆ¶

### 4. æ•°æ®å¯¼å…¥å‘å¯¼
**ç¼ºå°‘**: ç”¨æˆ·å‹å¥½çš„æ•°æ®å¯¼å…¥æµç¨‹
**éœ€è¦**:
- æ­¥éª¤å¼å¯¼å…¥å‘å¯¼
- å­—æ®µæ˜ å°„åŠŸèƒ½
- æ•°æ®ç±»å‹æ£€æµ‹
- å¯¼å…¥é¢„è§ˆå’Œç¡®è®¤

## ğŸš€ **éœ€è¦å®ç°çš„æ•°æ®è¾“å…¥åŠŸèƒ½**

### **åŠŸèƒ½1: CSVæ–‡ä»¶ä¸Šä¼ **

#### APIè®¾è®¡
```http
# 1. ä¸Šä¼ CSVæ–‡ä»¶
POST /api/reports/reports/{report_id}/upload_csv/
Content-Type: multipart/form-data

file: [CSVæ–‡ä»¶]
slice_id: "campaign_data"  # å¯é€‰ï¼Œé»˜è®¤ä¸º"default"

# å“åº”
{
  "slice_id": "campaign_data",
  "preview": {
    "columns": ["Campaign", "Cost", "Revenue"],
    "rows": [
      ["Facebook Ads", "50000", "125000"],
      ["Google Ads", "40000", "100000"]
    ],
    "total_rows": 150,
    "preview_rows": 10
  },
  "validation": {
    "errors": [],
    "warnings": ["Row 5: Cost value seems unusually high"]
  }
}

# 2. ç¡®è®¤å¯¼å…¥
POST /api/reports/reports/{report_id}/confirm_csv_import/
{
  "slice_id": "campaign_data",
  "column_mapping": {
    "Campaign": "campaign_name",
    "Cost": "cost_usd", 
    "Revenue": "revenue_usd"
  },
  "data_types": {
    "cost_usd": "float",
    "revenue_usd": "float"
  }
}
```

#### å®ç°ä»£ç 
```python
# backend/reports/views.py
from rest_framework.decorators import action
from rest_framework.response import Response
import pandas as pd
import csv

class ReportUploadView(APIView):
    
    @action(detail=True, methods=['post'])
    def upload_csv(self, request, pk=None):
        """ä¸Šä¼ CSVæ–‡ä»¶å¹¶é¢„è§ˆæ•°æ®"""
        report = self.get_object()
        
        if 'file' not in request.FILES:
            return Response({'error': 'No file provided'}, status=400)
        
        csv_file = request.FILES['file']
        slice_id = request.data.get('slice_id', 'default')
        
        try:
            # è¯»å–CSVæ–‡ä»¶
            content = csv_file.read().decode('utf-8')
            csv_reader = csv.reader(content.splitlines())
            rows = list(csv_reader)
            
            if not rows:
                return Response({'error': 'Empty file'}, status=400)
            
            columns = rows[0]
            data_rows = rows[1:]
            
            # æ•°æ®éªŒè¯
            validation_result = self._validate_csv_data(columns, data_rows)
            
            # ç”Ÿæˆé¢„è§ˆ
            preview_rows = data_rows[:10]  # åªæ˜¾ç¤ºå‰10è¡Œ
            
            return Response({
                'slice_id': slice_id,
                'preview': {
                    'columns': columns,
                    'rows': preview_rows,
                    'total_rows': len(data_rows),
                    'preview_rows': len(preview_rows)
                },
                'validation': validation_result
            })
            
        except Exception as e:
            return Response({'error': str(e)}, status=400)
    
    @action(detail=True, methods=['post'])
    def confirm_csv_import(self, request, pk=None):
        """ç¡®è®¤å¯¼å…¥CSVæ•°æ®"""
        report = self.get_object()
        slice_id = request.data.get('slice_id', 'default')
        column_mapping = request.data.get('column_mapping', {})
        
        # é‡æ–°è¯»å–å’Œå¤„ç†CSVæ•°æ®
        # åº”ç”¨åˆ—æ˜ å°„å’Œæ•°æ®ç±»å‹è½¬æ¢
        # æ›´æ–°æŠ¥å‘Šçš„slice_config
        
        # è·å–å½“å‰slice_config
        current_config = report.slice_config or {}
        
        # æ·»åŠ æ–°çš„sliceæ•°æ®
        if 'inline_result' not in current_config:
            current_config['inline_result'] = {}
        
        current_config['inline_result'][slice_id] = {
            'columns': mapped_columns,
            'rows': processed_rows
        }
        
        # ä¿å­˜æ›´æ–°
        report.slice_config = current_config
        report.save()
        
        return Response({
            'message': 'CSV data imported successfully',
            'slice_id': slice_id,
            'rows_imported': len(processed_rows)
        })
    
    def _validate_csv_data(self, columns, rows):
        """éªŒè¯CSVæ•°æ®è´¨é‡"""
        errors = []
        warnings = []
        
        # æ£€æŸ¥åˆ—å
        if not columns:
            errors.append("No column headers found")
        
        # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
        for i, row in enumerate(rows):
            if len(row) != len(columns):
                errors.append(f"Row {i+2}: Column count mismatch")
        
        # æ£€æŸ¥æ•°å€¼å­—æ®µ
        numeric_columns = self._detect_numeric_columns(columns, rows)
        for col_idx, col_name in enumerate(columns):
            if col_name in numeric_columns:
                for row_idx, row in enumerate(rows):
                    if col_idx < len(row):
                        try:
                            float(row[col_idx])
                        except ValueError:
                            warnings.append(f"Row {row_idx+2}, Column '{col_name}': Non-numeric value")
        
        return {'errors': errors, 'warnings': warnings}
```

### **åŠŸèƒ½2: æ•°æ®æºè¿æ¥å™¨**

#### æ•°æ®æºé…ç½®API
```http
# åˆ›å»ºæ•°æ®æºé…ç½®
POST /api/reports/data-sources/
{
  "id": "marketing_db",
  "name": "è¥é”€æ•°æ®åº“",
  "type": "postgresql",
  "connection": {
    "host": "db.company.com",
    "port": 5432,
    "database": "marketing",
    "username": "readonly_user",
    "password": "encrypted_password"
  },
  "tables": ["campaigns", "conversions", "costs"]
}

# åœ¨Reportä¸­ä½¿ç”¨æ•°æ®æº
PUT /api/reports/reports/{report_id}/
{
  "slice_config": {
    "external_query": {
      "data_source_id": "marketing_db",
      "query": "SELECT campaign_name, SUM(cost) as total_cost, SUM(revenue) as total_revenue FROM campaigns WHERE date_range BETWEEN ? AND ? GROUP BY campaign_name",
      "parameters": ["2024-01-01", "2024-03-31"]
    }
  }
}
```

#### å®ç°ä»£ç 
```python
# backend/reports/services/data_sources.py
class DataSourceConnector:
    
    def __init__(self, data_source_config):
        self.config = data_source_config
        self.connection = None
    
    def connect(self):
        """å»ºç«‹æ•°æ®æºè¿æ¥"""
        if self.config['type'] == 'postgresql':
            import psycopg2
            self.connection = psycopg2.connect(**self.config['connection'])
        elif self.config['type'] == 'mysql':
            import mysql.connector
            self.connection = mysql.connector.connect(**self.config['connection'])
        elif self.config['type'] == 'api':
            # HTTP APIè¿æ¥å™¨
            pass
    
    def execute_query(self, query, parameters=None):
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›ç»“æœ"""
        cursor = self.connection.cursor()
        cursor.execute(query, parameters or [])
        
        columns = [desc[0] for desc in cursor.description]
        rows = cursor.fetchall()
        
        return {
            'columns': columns,
            'rows': [list(row) for row in rows]
        }
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.connection:
            self.connection.close()

# åœ¨slices.pyä¸­é›†æˆæ•°æ®æº
def _load_external_data(slice_config):
    """åŠ è½½å¤–éƒ¨æ•°æ®æºæ•°æ®"""
    if 'external_query' not in slice_config:
        return []
    
    query_config = slice_config['external_query']
    data_source_id = query_config['data_source_id']
    
    # è·å–æ•°æ®æºé…ç½®
    data_source = DataSource.objects.get(id=data_source_id)
    
    # åˆ›å»ºè¿æ¥å™¨å¹¶æ‰§è¡ŒæŸ¥è¯¢
    connector = DataSourceConnector(data_source.config)
    connector.connect()
    
    try:
        result = connector.execute_query(
            query_config['query'],
            query_config.get('parameters', [])
        )
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        rows = []
        for row_data in result['rows']:
            row_dict = {}
            for i, col_name in enumerate(result['columns']):
                row_dict[col_name] = row_data[i]
            rows.append(row_dict)
        
        return rows
        
    finally:
        connector.close()
```

### **åŠŸèƒ½3: åœ¨çº¿æ•°æ®ç¼–è¾‘å™¨**

#### æ•°æ®ç¼–è¾‘API
```http
# è·å–å¯ç¼–è¾‘çš„æ•°æ®è¡¨æ ¼
GET /api/reports/reports/{report_id}/data_editor/{slice_id}/
{
  "columns": [
    {"name": "Campaign", "type": "text", "editable": true},
    {"name": "Cost", "type": "number", "editable": true},
    {"name": "Revenue", "type": "number", "editable": true},
    {"name": "ROI", "type": "number", "editable": false, "calculated": true}
  ],
  "rows": [
    {"id": 1, "Campaign": "Facebook Ads", "Cost": 50000, "Revenue": 125000, "ROI": 150},
    {"id": 2, "Campaign": "Google Ads", "Cost": 40000, "Revenue": 100000, "ROI": 150}
  ],
  "metadata": {
    "total_rows": 2,
    "editable": true,
    "last_modified": "2024-01-15T10:30:00Z"
  }
}

# æ›´æ–°å•ä¸ªå•å…ƒæ ¼
PATCH /api/reports/reports/{report_id}/data_editor/{slice_id}/rows/{row_id}/
{
  "field": "Cost",
  "value": 55000
}

# æ‰¹é‡æ›´æ–°
PATCH /api/reports/reports/{report_id}/data_editor/{slice_id}/bulk_update/
{
  "updates": [
    {"row_id": 1, "field": "Cost", "value": 55000},
    {"row_id": 2, "field": "Revenue", "value": 110000}
  ]
}

# æ·»åŠ æ–°è¡Œ
POST /api/reports/reports/{report_id}/data_editor/{slice_id}/rows/
{
  "Campaign": "TikTok Ads",
  "Cost": 30000,
  "Revenue": 90000
}

# åˆ é™¤è¡Œ
DELETE /api/reports/reports/{report_id}/data_editor/{slice_id}/rows/{row_id}/
```

### **åŠŸèƒ½4: æ•°æ®å¯¼å…¥å‘å¯¼**

#### å‘å¯¼APIæµç¨‹
```http
# 1. å¼€å§‹å¯¼å…¥å‘å¯¼
POST /api/reports/reports/{report_id}/import_wizard/start/
{
  "import_type": "csv",  # csv, excel, api, database
  "file": [æ–‡ä»¶] æˆ– "data_source_id": "external_db"
}

# 2. å­—æ®µæ˜ å°„æ­¥éª¤
POST /api/reports/reports/{report_id}/import_wizard/mapping/
{
  "session_id": "wizard_session_123",
  "field_mapping": {
    "source_field_1": "target_field_campaign",
    "source_field_2": "target_field_cost"
  },
  "data_types": {
    "target_field_cost": "float",
    "target_field_revenue": "float"
  }
}

# 3. æ•°æ®é¢„è§ˆå’ŒéªŒè¯
GET /api/reports/reports/{report_id}/import_wizard/preview/{session_id}/

# 4. å®Œæˆå¯¼å…¥
POST /api/reports/reports/{report_id}/import_wizard/complete/
{
  "session_id": "wizard_session_123",
  "slice_id": "campaign_data",
  "confirm": true
}
```

## ğŸ“Š **æ•°æ®è¾“å…¥å®Œæ•´æ¶æ„**

```
å‰ç«¯æ•°æ®è¾“å…¥ç•Œé¢
       â†“
    APIå±‚éªŒè¯
       â†“
   æ•°æ®å¤„ç†å±‚ (slices.py)
       â†“
  æ ‡å‡†åŒ–å­˜å‚¨ (slice_config)
       â†“
   ç»„è£…è¾“å‡º (assembler.py)
```

## ğŸ”§ **å®ç°ä¼˜å…ˆçº§å»ºè®®**

### **é«˜ä¼˜å…ˆçº§ (ç«‹å³å®ç°)**
1. **CSVæ–‡ä»¶ä¸Šä¼ ** - æœ€å¸¸ç”¨çš„æ•°æ®è¾“å…¥æ–¹å¼
2. **åœ¨çº¿æ•°æ®ç¼–è¾‘** - å°æ•°æ®é‡å¿«é€Ÿä¿®æ”¹
3. **APIæ•°æ®æ›´æ–°** - ç¨‹åºåŒ–æ•°æ®è¾“å…¥

### **ä¸­ä¼˜å…ˆçº§ (åç»­å®ç°)**
1. **Excelæ–‡ä»¶æ”¯æŒ** - ä¼ä¸šç”¨æˆ·å¸¸ç”¨
2. **æ•°æ®å¯¼å…¥å‘å¯¼** - æå‡ç”¨æˆ·ä½“éªŒ
3. **æ•°æ®éªŒè¯è§„åˆ™** - æ•°æ®è´¨é‡ä¿è¯

### **ä½ä¼˜å…ˆçº§ (é•¿æœŸè§„åˆ’)**
1. **å¤–éƒ¨æ•°æ®æºè¿æ¥** - å¤æ‚é›†æˆéœ€æ±‚
2. **å®æ—¶æ•°æ®åŒæ­¥** - é«˜çº§åŠŸèƒ½
3. **æ•°æ®è½¬æ¢ç®¡é“** - ETLåŠŸèƒ½

## ğŸ’¡ **å¿«é€ŸåŸå‹å®ç°å»ºè®®**

åˆ›å»ºä¸€ä¸ªç®€å•çš„CSVä¸Šä¼ åŠŸèƒ½ä½œä¸ºèµ·ç‚¹ï¼š

```python
# åœ¨ç°æœ‰çš„ReportUploadViewä¸­æ·»åŠ 
@action(detail=True, methods=['post'])
def upload_data(self, request, pk=None):
    """ç®€å•çš„æ•°æ®ä¸Šä¼ æ¥å£"""
    report = self.get_object()
    
    # æ”¯æŒJSONæ ¼å¼ç›´æ¥ä¸Šä¼ 
    if 'json_data' in request.data:
        data = request.data['json_data']
        slice_id = request.data.get('slice_id', 'default')
        
        # æ›´æ–°slice_config
        current_config = report.slice_config or {}
        if 'inline_result' not in current_config:
            current_config['inline_result'] = {}
        current_config['inline_result'][slice_id] = data
        
        report.slice_config = current_config
        report.save()
        
        return Response({'message': 'Data uploaded successfully'})
    
    return Response({'error': 'Invalid data format'}, status=400)
```

**æ€»ç»“**: ä½ å®Œå…¨è¯´å¯¹äº†ï¼æ•°æ®è¾“å…¥ç¡®å®æ˜¯missing pieceã€‚ç°åœ¨çš„ç³»ç»Ÿèƒ½å¤„ç†æ•°æ®ï¼Œä½†ç¼ºå°‘ä¾¿æ·çš„æ•°æ®è¾“å…¥æ–¹å¼ã€‚å»ºè®®ä¼˜å…ˆå®ç°CSVä¸Šä¼ å’Œåœ¨çº¿ç¼–è¾‘åŠŸèƒ½ã€‚


